import matplotlib.pyplot as plt
from matplotlib import rcParams


fontsize = 13
rcParams['font.family'] = 'serif'
rcParams['font.sans-serif'] = ['Times New Roman']
rcParams['font.size'] = fontsize
rcParams['mathtext.fontset'] = 'stix'
rcParams['axes.titlesize'] = fontsize
rcParams['axes.labelsize'] = fontsize
rcParams['text.usetex'] = True
rcParams["savefig.dpi"] = 150

unet_train = [0.006900343340439423, 0.0050889107453985895, 0.004520913553749474, 0.004107073874932468, 0.0039159601230531, 0.003814652283990697, 0.0036245445272445357, 0.003524664639223077, 0.0034140829267697488, 0.003102519821780546, 0.003256549684505268, 0.002887468723778576, 0.003000715361888899, 0.0027417346726724243, 0.0026243057073139257, 0.0029261817057054332, 0.0025256111417674308, 0.0026771737535015174, 0.0024192080937467902, 0.0023673057348974846, 0.0025990906992803277, 0.002286260932368355, 0.002218021816790574, 0.0024670586804191813, 0.002185837308265192, 0.002122499167802478, 0.002619204476082492, 0.002165967176737654, 0.0020651326234734885, 0.002129493028130372, 0.0020964944210794434, 0.0019522355093645237, 0.001925449886302599, 0.001878230915376662, 0.001840470446900385, 0.0023011607645369242, 0.0019660169948118667, 0.001830690335090743, 0.001968301030781874, 0.0017862557347987254, 0.0017376276871441097, 0.0016999078373438432, 0.0016683745101196228, 0.0020580812171836567, 0.0017918098589705274, 0.0016657858721788336, 0.00162911158137984, 0.0016025240692456519, 0.0015740755131663756, 0.0016547843059202757]
unet_eval = [0.006914643212224858, 0.006608961235734476, 0.00614931498326609, 0.0061489697334851596, 0.006095873452960306, 0.00582339186603645, 0.005689661405448026, 0.0059706938050302395, 0.005582963761735789, 0.0057177603421423, 0.00581069503069156, 0.005367804188821768, 0.005702688354110347, 0.005436251473844431, 0.005469121671659425, 0.005617021250170085, 0.005581296812307936, 0.005626930963308653, 0.005443426623534456, 0.0055170816099778695, 0.005383943539753461, 0.005746943070714725, 0.005587655371377971, 0.005417957741131786, 0.005713666325879283, 0.0054746151658569935, 0.005648053303935683, 0.005589305923794253, 0.005745597246978946, 0.005505974321465963, 0.005412922755558695, 0.0053231139477508465, 0.00576797328752275, 0.0059005503977074825, 0.005630194167992112, 0.005377364606891152, 0.005585851152714208, 0.005566281015719093, 0.005615202292486213, 0.005702147214829668, 0.0056314745364922925, 0.005714443549500635, 0.005727346965111133, 0.005505601121132478, 0.005519314203411341, 0.00554395840890173, 0.005534956781740675, 0.005417751595219736, 0.005592955806294571] #, 0.007211969203071145]
losses_train = [0.005898741587888071, 0.003547487730150364, 0.0027596050791228325, 0.0023374681041065893, 0.001992224062564361, 0.001770377848179069, 0.0016266967306776386, 0.0015078698212228157, 0.0014277665742174388, 0.001357323404266485, 0.0013000128873251182, 0.001246111243363759, 0.001227221375702112, 0.001171377942346648, 0.0011329443680161656, 0.0010997750076740186, 0.0010896383184970401, 0.0010596688701182914, 0.0010280293769296322, 0.0010173938081259435, 0.0009913231867964276, 0.0009677276271583442, 0.000967290008692006, 0.0009392077279599224, 0.0009286069950936748, 0.000908271674514901, 0.0009031899301991546, 0.0008899625040352119, 0.0008729685050875731, 0.0008604498821125744, 0.0008498156052971665, 0.000842282176009148, 0.000834297576072917, 0.0008185987974871856, 0.0008121420464751932, 0.000802212124834542, 0.0008045180239163721, 0.0007917085035353057, 0.0007818054710131553, 0.0007797989400145146, 0.0007691577276911712, 0.0007829573848244873, 0.000755171905841849, 0.0007530943195934073, 0.000745191481656928, 0.0007381474963898725, 0.0007311152801168214, 0.0007278456815211635, 0.0007259264689475634, 0.0007128337374140443]
losses_eval = [0.0040231898370326116, 0.0030466626442425737, 0.0027434797403887074, 0.002300576452872408, 0.002095518395784512, 0.001908167124306025, 0.0017805649887082304, 0.001799929992513967, 0.001739432726955728, 0.0017130517828234082, 0.0016326778787481536, 0.001650594149156614, 0.0015765050439637285, 0.0015651605542490795, 0.0015537516874381818, 0.001548594865033117, 0.0014685704954487903, 0.0015039879185070467, 0.001366906968437752, 0.001417044104622006, 0.0013170917310817226, 0.0013691869917637435, 0.0014474129847066987, 0.0014332006397075102, 0.0013029468955995445, 0.001406395041976343, 0.0014067405062976115, 0.0013937993261499116, 0.0013920646439315007, 0.0014189312849800192, 0.0013738950470268663, 0.001333005058658899, 0.0012939286868760898, 0.0013858666144224425, 0.0012455069715709487, 0.001363028939589278, 0.0012820704341836417, 0.0014252620679968987, 0.0013387445850635274, 0.0013317074689299649, 0.0013103420407526453, 0.0012174841487465158, 0.0011973118512335604, 0.0013102352233921287, 0.0013423254925979107, 0.0012894010279058713, 0.0012489122381270385, 0.0013374998728544975, 0.0012486702730412538] #, 0.0013488385460872707]
train_steps_list = [epoch for epoch in range(50)]
eval_steps_list = [epoch for epoch in range(1, 50)]
plt.plot(eval_steps_list, unet_eval, label='Unet Eval Loss')
plt.plot(train_steps_list, unet_train, label='Unet Train Loss')
plt.plot(eval_steps_list, losses_eval, label='Transformer Eval Loss')
plt.plot(train_steps_list, losses_train, label='Transformer Train Loss')
plt.legend(loc='best', shadow=True, fontsize='medium')
plt.xlabel(r'Training Epochs')
plt.ylabel('L1 Loss')
plt.savefig(f'results.png')